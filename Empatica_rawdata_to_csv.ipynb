{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8d6d2a8-0ba7-4f78-b91e-e53a2474e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679198-4994-43c5-b4d2-1b0d0eee7bfe",
   "metadata": {},
   "source": [
    "# The following sections extract and concatenate data from the avro files, seperately for each date, to one continous csv with UNIX timestamps and corresponding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27db2431-44c3-472a-b1eb-e389bbe830d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerometer data \n",
    "sub_output_folder = 'Acceleration'\n",
    "dfs = pd.DataFrame()\n",
    "dates = os.listdir(participant_data_path) #all date-folders available \n",
    "\n",
    "#create output directory if it doesn't exist\n",
    "#if output directory exists- list files (to avoid redoing them)\n",
    "if not os.path.exists(os.path.join(output_folder, sub_output_folder)):\n",
    "    os.mkdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = []\n",
    "else:\n",
    "    csvFiles = os.listdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = [re.findall('\\d{4}-\\d{2}-\\d{2}',f)[0] for f in csvFiles]\n",
    "        \n",
    "\n",
    "for d in dates:\n",
    "    if d in csvDates: #if there is already csv file for specific date- skip\n",
    "        continue\n",
    "    else:\n",
    "        folder = os.listdir(participant_data_path+d) # list folders (for each user) within the date-folder \n",
    "        if len(re.findall('^'+userID,folder[0]))>0: #check if data is available for the specific userID\n",
    "            subfolder1 = [f for f in folder if re.match('^'+userID,f)][0] #choose only the user we want\n",
    "            subfolder = participant_data_path+d+'\\\\'+subfolder1+'\\\\raw_data\\\\v6\\\\' #path to avro files (within user -> date)\n",
    "            #print(subfolder)\n",
    "            files = os.listdir(subfolder) #list of avro files\n",
    "            for ff in files: #loop through files to read and store data\n",
    "                avro_file = subfolder+ff\n",
    "                reader = DataFileReader(open(avro_file, \"rb\"), DatumReader())\n",
    "                schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "                data = []\n",
    "                for datum in reader:\n",
    "                    data = datum\n",
    "                reader.close()\n",
    "\n",
    "                acc = data[\"rawData\"][\"accelerometer\"] #access specific metric \n",
    "                startSeconds = acc[\"timestampStart\"] / 1000000 # convert timestamp to seconds\n",
    "                timeSeconds = list(range(0,len(acc['x'])))\n",
    "                timeUNIX = [t/acc[\"samplingFrequency\"]+startSeconds for t in timeSeconds]\n",
    "                delta_physical = acc[\"imuParams\"][\"physicalMax\"] - acc[\"imuParams\"][\"physicalMin\"]\n",
    "                delta_digital = acc[\"imuParams\"][\"digitalMax\"] - acc[\"imuParams\"][\"digitalMin\"]\n",
    "                acc['x'] = [val*delta_physical/delta_digital for val in acc[\"x\"]]\n",
    "                acc['y'] = [val*delta_physical/delta_digital for val in acc[\"y\"]]\n",
    "                acc['z'] = [val*delta_physical/delta_digital for val in acc[\"z\"]]\n",
    "\n",
    "                df_acTot = pd.concat([pd.DataFrame(timeUNIX), pd.DataFrame(acc['x']),pd.DataFrame(acc['y']),pd.DataFrame(acc['z'])],axis = 1)\n",
    "                df_acTot.columns = ['time','x','y','z']\n",
    "                dfs = pd.concat([dfs,df_acTot])\n",
    "\n",
    "            dfs=dfs.reset_index()\n",
    "            dfs.to_csv(output_folder+sub_output_folder+'\\\\empatica_ac_'+d+'.csv')\n",
    "            dfs = pd.DataFrame()\n",
    "#dfs=dfs.reset_index()    \n",
    "#dfs.to_csv(r'C:\\Users\\Noy\\Desktop\\sensors_project\\SummData\\empatica_ac_'+dates[0]+'_'+dates[-1][8:10]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f8935c5-cf63-4d99-9174-3da7f8171d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature data \n",
    "sub_output_folder = 'Temperature'\n",
    "dfs = pd.DataFrame()\n",
    "dates = os.listdir(participant_data_path) #all date-folders available \n",
    "\n",
    "#create output directory if doesn't exist\n",
    "#if output directory exists- list files\n",
    "if not os.path.exists(os.path.join(output_folder, sub_output_folder)):\n",
    "    os.mkdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = []\n",
    "else:\n",
    "    csvFiles = os.listdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = [re.findall('\\d{4}-\\d{2}-\\d{2}',f)[0] for f in csvFiles]\n",
    "        \n",
    "\n",
    "for d in dates:\n",
    "    if d in csvDates:\n",
    "        continue\n",
    "    else:\n",
    "        folder = os.listdir(participant_data_path+d) # list folders (for each user) within the date-folde\n",
    "        if len(re.findall('^'+userID,folder[0]))>0: #check if data is available for the specific userID\n",
    "            subfolder1 = [f for f in folder if re.match('^'+userID,f)][0] #choose only the user we want\n",
    "            subfolder = participant_data_path+d+'\\\\'+subfolder1+'\\\\raw_data\\\\v6\\\\' #path to avro files (within user -> date)\n",
    "            #print(subfolder)\n",
    "            files = os.listdir(subfolder) #list of avro files\n",
    "            for ff in files: #loop through files to read and store data\n",
    "                avro_file = subfolder+ff\n",
    "                reader = DataFileReader(open(avro_file, \"rb\"), DatumReader())\n",
    "                schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "                data = []\n",
    "                for datum in reader:\n",
    "                    data = datum\n",
    "                reader.close()\n",
    "\n",
    "                temp = data['rawData']['temperature']\n",
    "                startSeconds = temp[\"timestampStart\"] / 1000000\n",
    "                timeSeconds = list(range(0,len(temp['values'])))\n",
    "                timeUNIXtemp = [t/temp[\"samplingFrequency\"]+startSeconds for t in timeSeconds]\n",
    "                #datetime_timetemp = [datetime.utcfromtimestamp(x) for x in timeUNIXtemp]\n",
    "\n",
    "                df_temp = pd.concat([pd.DataFrame(timeUNIXtemp), pd.DataFrame(temp['values'])],axis = 1)                \n",
    "                df_temp.columns = ['time','tmp']\n",
    "                dfs = pd.concat([dfs,df_temp])\n",
    "\n",
    "            dfs=dfs.reset_index()\n",
    "            dfs.to_csv(output_folder+sub_output_folder+'\\\\empatica_temp_'+d+'.csv')\n",
    "            dfs = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44ee42e6-d9bb-4c37-ba93-5ef64b4142dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps data \n",
    "sub_output_folder = 'Steps'\n",
    "dfs = pd.DataFrame()\n",
    "dates = os.listdir(participant_data_path) #all date-folders available \n",
    "\n",
    "#create output directory if doesn't exist\n",
    "#if output directory exists- list files\n",
    "if not os.path.exists(os.path.join(output_folder, sub_output_folder)):\n",
    "    os.mkdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = []\n",
    "else:\n",
    "    csvFiles = os.listdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = [re.findall('\\d{4}-\\d{2}-\\d{2}',f)[0] for f in csvFiles]\n",
    "        \n",
    "\n",
    "for d in dates:\n",
    "    if d in csvDates:\n",
    "        continue\n",
    "    else:\n",
    "        folder = os.listdir(participant_data_path+d) # list folders (for each user) within the date-folde\n",
    "        if len(re.findall('^'+userID,folder[0]))>0: #check if data is available for the specific userID\n",
    "            subfolder1 = [f for f in folder if re.match('^'+userID,f)][0] #choose only the user we want\n",
    "            subfolder = participant_data_path+d+'\\\\'+subfolder1+'\\\\raw_data\\\\v6\\\\' #path to avro files (within user -> date)\n",
    "            #print(subfolder)\n",
    "            files = os.listdir(subfolder) #list of avro files\n",
    "            for ff in files: #loop through files to read and store data\n",
    "                avro_file = subfolder+ff\n",
    "                reader = DataFileReader(open(avro_file, \"rb\"), DatumReader())\n",
    "                schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "                data = []\n",
    "                for datum in reader:\n",
    "                    data = datum\n",
    "                reader.close()\n",
    "\n",
    "                temp = data['rawData']['steps']\n",
    "                startSeconds = temp[\"timestampStart\"] / 1000000\n",
    "                timeSeconds = list(range(0,len(temp['values'])))\n",
    "                timeUNIXtemp = [t/temp[\"samplingFrequency\"]+startSeconds for t in timeSeconds]\n",
    "                #datetime_timetemp = [datetime.utcfromtimestamp(x) for x in timeUNIXtemp]\n",
    "\n",
    "                df_temp = pd.concat([pd.DataFrame(timeUNIXtemp), pd.DataFrame(temp['values'])],axis = 1)                \n",
    "                df_temp.columns = ['time','steps']\n",
    "                dfs = pd.concat([dfs,df_temp])\n",
    "\n",
    "            dfs=dfs.reset_index()\n",
    "            dfs.to_csv(output_folder+sub_output_folder+'\\\\empatica_steps_'+d+'.csv')\n",
    "            dfs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e9bfb-ecd9-46a5-acf4-de5b67bd95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eda data\n",
    "sub_output_folder = 'EDA'\n",
    "dfs = pd.DataFrame()\n",
    "dates = os.listdir(participant_data_path) #all date-folders available \n",
    "\n",
    "#create output directory if doesn't exist\n",
    "#if output directory exists- list files\n",
    "if not os.path.exists(os.path.join(output_folder, sub_output_folder)):\n",
    "    os.mkdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = []\n",
    "else:\n",
    "    csvFiles = os.listdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = [re.findall('\\d{4}-\\d{2}-\\d{2}',f)[0] for f in csvFiles]\n",
    "        \n",
    "\n",
    "for d in dates:\n",
    "    if d in csvDates:\n",
    "        continue\n",
    "    else:\n",
    "        folder = os.listdir(participant_data_path+d) # list folders (for each user) within the date-folde\n",
    "        if len(re.findall('^'+userID,folder[0]))>0: #check if data is available for the specific userID\n",
    "            subfolder1 = [f for f in folder if re.match('^'+userID,f)][0] #choose only the user we want\n",
    "            subfolder = participant_data_path+d+'\\\\'+subfolder1+'\\\\raw_data\\\\v6\\\\' #path to avro files (within user -> date)\n",
    "            #print(subfolder)\n",
    "            files = os.listdir(subfolder) #list of avro files\n",
    "            for ff in files: #loop through files to read and store data\n",
    "                avro_file = subfolder+ff\n",
    "                reader = DataFileReader(open(avro_file, \"rb\"), DatumReader())\n",
    "                schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "                data = []\n",
    "                for datum in reader:\n",
    "                    data = datum\n",
    "                reader.close()\n",
    "\n",
    "                temp = data['rawData']['eda']\n",
    "                startSeconds = temp[\"timestampStart\"] / 1000000\n",
    "                timeSeconds = list(range(0,len(temp['values'])))\n",
    "                timeUNIXtemp = [t/temp[\"samplingFrequency\"]+startSeconds for t in timeSeconds]\n",
    "                #datetime_timetemp = [datetime.utcfromtimestamp(x) for x in timeUNIXtemp]\n",
    "\n",
    "                df_temp = pd.concat([pd.DataFrame(timeUNIXtemp), pd.DataFrame(temp['values'])],axis = 1)                \n",
    "                df_temp.columns = ['time','eda']\n",
    "                dfs = pd.concat([dfs,df_temp])\n",
    "\n",
    "            dfs=dfs.reset_index()\n",
    "            dfs.to_csv(output_folder+sub_output_folder+'\\\\empatica_eda_'+d+'.csv')\n",
    "            dfs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a83c03-ba87-421c-a509-369a19149157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bvp data\n",
    "sub_output_folder = 'BVP'\n",
    "dfs = pd.DataFrame()\n",
    "dates = os.listdir(participant_data_path) #all date-folders available \n",
    "\n",
    "#create output directory if doesn't exist\n",
    "#if output directory exists- list files\n",
    "if not os.path.exists(os.path.join(output_folder, sub_output_folder)):\n",
    "    os.mkdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = []\n",
    "else:\n",
    "    csvFiles = os.listdir(os.path.join(output_folder, sub_output_folder))\n",
    "    csvDates = [re.findall('\\d{4}-\\d{2}-\\d{2}',f)[0] for f in csvFiles]\n",
    "        \n",
    "\n",
    "for d in dates:\n",
    "    if d in csvDates:\n",
    "        continue\n",
    "    else:\n",
    "        folder = os.listdir(participant_data_path+d) # list folders (for each user) within the date-folde\n",
    "        if len(re.findall('^'+userID,folder[0]))>0: #check if data is available for the specific userID\n",
    "            subfolder1 = [f for f in folder if re.match('^'+userID,f)][0] #choose only the user we want\n",
    "            subfolder = participant_data_path+d+'\\\\'+subfolder1+'\\\\raw_data\\\\v6\\\\' #path to avro files (within user -> date)\n",
    "            #print(subfolder)\n",
    "            files = os.listdir(subfolder) #list of avro files\n",
    "            for ff in files: #loop through files to read and store data\n",
    "                avro_file = subfolder+ff\n",
    "                reader = DataFileReader(open(avro_file, \"rb\"), DatumReader())\n",
    "                schema = json.loads(reader.meta.get('avro.schema').decode('utf-8'))\n",
    "                data = []\n",
    "                for datum in reader:\n",
    "                    data = datum\n",
    "                reader.close()\n",
    "\n",
    "                temp = data['rawData']['bvp']\n",
    "                startSeconds = temp[\"timestampStart\"] / 1000000\n",
    "                timeSeconds = list(range(0,len(temp['values'])))\n",
    "                timeUNIXtemp = [t/temp[\"samplingFrequency\"]+startSeconds for t in timeSeconds]\n",
    "                #datetime_timetemp = [datetime.utcfromtimestamp(x) for x in timeUNIXtemp]\n",
    "\n",
    "                df_temp = pd.concat([pd.DataFrame(timeUNIXtemp), pd.DataFrame(temp['values'])],axis = 1)  \n",
    "                if len(df_temp) !=0:\n",
    "                    df_temp.columns = ['time','bvp']\n",
    "                dfs = pd.concat([dfs,df_temp])\n",
    "\n",
    "            dfs=dfs.reset_index()\n",
    "            dfs.to_csv(output_folder+sub_output_folder+'\\\\empatica_bvp_'+d+'.csv')\n",
    "            dfs = pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
